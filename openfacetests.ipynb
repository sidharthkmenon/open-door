{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openface\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ketanagrawal/anaconda2/lib/python2.7/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "with CustomObjectScope({'tf': tf}):\n",
    "    model = load_model('./nn4.small2.v1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_97 (ZeroPadding2 (None, 102, 102, 3)  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d_97[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 48, 48, 64)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_98 (ZeroPadding2 (None, 50, 50, 64)   0           activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 24, 24, 64)   0           zero_padding2d_98[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 24, 24, 64)   0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_99 (ZeroPadding2 (None, 26, 26, 64)   0           activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_99[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 24, 24, 192)  0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_100 (ZeroPadding (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 12, 12, 192)  0           zero_padding2d_100[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 5, 5, 192)    0           max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_101 (ZeroPadding (None, 14, 14, 96)   0           activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_102 (ZeroPadding (None, 16, 16, 16)   0           activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_101[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_102[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_103 (ZeroPadding (None, 12, 12, 32)   0           activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 12, 12, 256)  0           activation_156[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 zero_padding2d_103[0][0]         \n",
      "                                                                 activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "power2_3b (Lambda)              (None, 12, 12, 256)  0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 4, 4, 256)    0           power2_3b[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mult9_3b (Lambda)               (None, 4, 4, 256)    0           average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sqrt_3b (Lambda)                (None, 4, 4, 256)    0           mult9_3b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_104 (ZeroPadding (None, 14, 14, 96)   0           activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_105 (ZeroPadding (None, 16, 16, 32)   0           activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       sqrt_3b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_104[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_105[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_106 (ZeroPadding (None, 12, 12, 64)   0           activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 12, 12, 320)  0           activation_162[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "                                                                 zero_padding2d_106[0][0]         \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_107 (ZeroPadding (None, 14, 14, 128)  0           activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_108 (ZeroPadding (None, 16, 16, 32)   0           activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_107[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_108[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 5, 5, 320)    0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_109 (ZeroPadding (None, 6, 6, 320)    0           max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 6, 6, 640)    0           activation_168[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 zero_padding2d_109[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "power2_4a (Lambda)              (None, 6, 6, 640)    0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 2, 2, 640)    0           power2_4a[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mult9_4a (Lambda)               (None, 2, 2, 640)    0           average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sqrt_4a (Lambda)                (None, 2, 2, 640)    0           mult9_4a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_110 (ZeroPadding (None, 8, 8, 96)     0           activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_111 (ZeroPadding (None, 10, 10, 32)   0           activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       sqrt_4a[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_110[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_111[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_112 (ZeroPadding (None, 6, 6, 128)    0           activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 6, 6, 640)    0           activation_172[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "                                                                 zero_padding2d_112[0][0]         \n",
      "                                                                 activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4e_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4e_5x5_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 6, 6, 160)    0           inception_4e_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 6, 6, 64)     0           inception_4e_5x5_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_113 (ZeroPadding (None, 8, 8, 160)    0           activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_114 (ZeroPadding (None, 10, 10, 64)   0           activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_113[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_114[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4e_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4e_5x5_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 2, 2, 640)    0           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 256)    0           inception_4e_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 128)    0           inception_4e_5x5_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_115 (ZeroPadding (None, 3, 3, 640)    0           max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 3, 3, 1024)   0           activation_178[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "                                                                 zero_padding2d_115[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "power2_5a (Lambda)              (None, 3, 3, 1024)   0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 1, 1, 1024)   0           power2_5a[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mult9_5a (Lambda)               (None, 1, 1, 1024)   0           average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sqrt_5a (Lambda)                (None, 1, 1, 1024)   0           mult9_5a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_116 (ZeroPadding (None, 5, 5, 96)     0           activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       sqrt_5a[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_116[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_117 (ZeroPadding (None, 3, 3, 96)     0           activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 3, 3, 736)    0           activation_182[0][0]             \n",
      "                                                                 zero_padding2d_117[0][0]         \n",
      "                                                                 activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 1, 1, 736)    0           concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_118 (ZeroPadding (None, 5, 5, 96)     0           activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_118[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_119 (ZeroPadding (None, 3, 3, 96)     0           activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 3, 3, 736)    0           activation_186[0][0]             \n",
      "                                                                 zero_padding2d_119[0][0]         \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 1, 1, 736)    0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 736)          0           average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 128)          94336       flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,743,280\n",
      "Trainable params: 3,733,968\n",
      "Non-trainable params: 9,312\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.layers[163].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736,)\n"
     ]
    }
   ],
   "source": [
    "get_flatten_layer_output = K.function([model.layers[0].input], [model.layers[163].output])\n",
    "# start = time.time()\n",
    "img1 = cv2.imread('/Users/ketanagrawal/Desktop/image-test/parkerface.jpeg', 1)\n",
    "bb = detect_largest_face2(img1)\n",
    "#     x, y, w, h = detect_largest_face(img1)\n",
    "# print \"Face detection took %s secs\" % (time.time() - start)\n",
    "\n",
    "# start = time.time()\n",
    "#     cv2.imshow('largest face', img1[y:y+h, x:x+w])\n",
    "#     cv2.waitKey()\n",
    "#     if img_to_encoding.align is None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    bb = detect_largest_face2(img1)\n",
    "    img1 = img_to_encoding.align.align(96, img1, bb, landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(img/255.0, decimals=12)\n",
    "    img = np.array([img])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it():\n",
    "    X_data, Y_data, _, _, _ = np.load('TODO: filename')\n",
    "    X_data = [process_image(x) for x in X_data]\n",
    "    intermediate_output = [get_flatten_layer_output([x]) for x in X_data]\n",
    "    return intermediate_output, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coolModel(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    model = Dense(256)(X_input)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(64, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(16, activation='relu')(model)\n",
    "    model = Dropout(0.125)(model) \n",
    "    model = Dense(1, activation='sigmoid')(model)\n",
    "    model = Model(inputs=X_input, outputs=model, name='cool model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://github.com/obieda01/Deep-Learning-Specialization-Coursera/blob/master/Course%204%20-%20Convolutional%20Neural%20Networks/Week%204/Face%20Recognition/Face%20Recognition%20for%20the%20Happy%20House%20-%20%20v1.ipynb\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "    pos_dist = tf.reduce_sum(tf.squared_difference(anchor, positive))\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
    "    neg_dist = tf.reduce_sum(tf.squared_difference(anchor, negative))\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    maxi = tf.maximum(basic_loss, 0.0)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam= keras.optimizers.Adam()\n",
    "model.compile(optimizer='adam', loss=triplet_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(img_path, model):\n",
    "    start = time.time()\n",
    "    img1 = cv2.imread(img_path, 1)\n",
    "    bb = detect_largest_face2(img1)\n",
    "#     x, y, w, h = detect_largest_face(img1)\n",
    "    print \"Face detection took %s secs\" % (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "#     cv2.imshow('largest face', img1[y:y+h, x:x+w])\n",
    "#     cv2.waitKey()\n",
    "#     if img_to_encoding.align is None:\n",
    "#         facePredictor = '/Users/ketanagrawal/openface/models/dlib/shape_predictor_68_face_landmarks.dat'\n",
    "#         img_to_encoding.align = openface.AlignDlib(facePredictor)\n",
    "#     print \"Face alignment part 1 took %s secs\" % (time.time() - start)\n",
    "#     s = time.time()\n",
    "#     bb = dlib.rectangle(x, y, x + w, y + h)\n",
    "    img1 = img_to_encoding.align.align(96, img1, bb, landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "#     print \"Face alignment part 2 took %s secs\" % (time.time() - s)\n",
    "    print \"Face alignment took %s secs\" % (time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(img/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    print \"Forward pass took %s secs\" % (time.time() - start)\n",
    "    return embedding\n",
    "\n",
    "facePredictor = '/Users/ketanagrawal/openface/models/dlib/shape_predictor_68_face_landmarks.dat'\n",
    "img_to_encoding.align = openface.AlignDlib(facePredictor)\n",
    "\n",
    "def detect_largest_face2(img):\n",
    "    return img_to_encoding.align.getLargestFaceBoundingBox(img)\n",
    "\n",
    "def detect_largest_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_boxes = detect_largest_face.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    face_areas = [w*h for x, y, w, h in face_boxes]\n",
    "    x, y, w, h = face_boxes[face_areas.index(max(face_areas))]\n",
    "    return dlib.rectangle(x, y, x + w, y + h)\n",
    "\n",
    "detect_largest_face.face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# def get_cropped_face(img_path):\n",
    "#     img = cv2.imread(img_path, 1)\n",
    "#     #TODO: take out manual resizing completely\n",
    "#     #\n",
    "#     face_box = detect_largest_face(img)\n",
    "#     img_cropped = img[y:y+h, x:x+w]\n",
    "#     img_cropped = cv2.resize(img_cropped, (96, 96))\n",
    "#     cv2.imshow('cropped', img_cropped)\n",
    "#     cv2.waitKey()\n",
    "#     return img_cropped, face_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection took 0.706151008606 secs\n",
      "Face alignment took 0.00460696220398 secs\n",
      "Forward pass took 0.0373001098633 secs\n",
      "Face detection took 0.254812002182 secs\n",
      "Face alignment took 0.00440788269043 secs\n",
      "Forward pass took 0.0595650672913 secs\n",
      "Face detection took 0.247279882431 secs\n",
      "Face alignment took 0.00497007369995 secs\n",
      "Forward pass took 0.0427491664886 secs\n",
      "Face detection took 0.0450839996338 secs\n",
      "Face alignment took 0.00463008880615 secs\n",
      "Forward pass took 0.0341148376465 secs\n",
      "Face detection took 0.0283031463623 secs\n",
      "Face alignment took 0.00390481948853 secs\n",
      "Forward pass took 0.0355129241943 secs\n",
      "Face detection took 0.0275769233704 secs\n",
      "Face alignment took 0.00397205352783 secs\n",
      "Forward pass took 0.0435268878937 secs\n",
      "Face detection took 0.028028011322 secs\n",
      "Face alignment took 0.00429391860962 secs\n",
      "Forward pass took 0.0337491035461 secs\n",
      "Face detection took 0.0275950431824 secs\n",
      "Face alignment took 0.00384593009949 secs\n",
      "Forward pass took 0.0322489738464 secs\n"
     ]
    }
   ],
   "source": [
    "database = {}\n",
    "database['ketan'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/ketan-1.jpg', model)\n",
    "database['sid'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/sid-1.jpeg', model)\n",
    "database['parker'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/parkerface.jpeg', model)\n",
    "database['aditya'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/aditya-1.jpg', model)\n",
    "database['aditya'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/aditya-1.jpg', model)\n",
    "database['aditya'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/aditya-1.jpg', model)\n",
    "database['aditya'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/aditya-1.jpg', model)\n",
    "database['aditya'] = img_to_encoding('/Users/ketanagrawal/Desktop/image-test/aditya-1.jpg', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11695807  0.0479257  -0.02169226  0.08518837  0.03476244  0.1282892\n",
      "  -0.0044486  -0.226699    0.14711022 -0.04599588 -0.02680009  0.07860252\n",
      "  -0.0890829   0.04648315 -0.07148203  0.00265849 -0.070216    0.07054456\n",
      "  -0.00763653 -0.10913508  0.008445   -0.03583751 -0.05542693  0.14082219\n",
      "   0.09315073 -0.03337851 -0.10274325 -0.01445491 -0.00047704  0.05960917\n",
      "   0.17783956  0.06275218 -0.08754221 -0.07426174  0.02352531  0.11968327\n",
      "  -0.12123275 -0.10547408 -0.0139121   0.07404707  0.07273468  0.0941164\n",
      "   0.00544526 -0.03143573  0.0590634  -0.13778393  0.02667193 -0.00500333\n",
      "   0.08644373 -0.0814798  -0.02033384 -0.04388687  0.10945784 -0.10921692\n",
      "   0.03982809  0.13877183 -0.06106444  0.24127991 -0.01309673 -0.00177161\n",
      "  -0.11365721  0.14090435  0.14560008 -0.13199224  0.06219028  0.10357567\n",
      "   0.04821612 -0.08780783 -0.15268555  0.15043259  0.05257808  0.15013172\n",
      "   0.02377413  0.07691078  0.00340313  0.02818717 -0.03454704 -0.09512714\n",
      "  -0.10596297 -0.10750516  0.01972636  0.17497547  0.02106167 -0.00776615\n",
      "  -0.09239972 -0.02610186  0.00644196 -0.04095658 -0.08838519 -0.05504252\n",
      "  -0.00032389 -0.01301208  0.11309287 -0.05482616  0.14843126  0.05743548\n",
      "  -0.06896828 -0.00655557  0.04318861  0.12293422 -0.00325702 -0.08601569\n",
      "  -0.04710708 -0.02930225 -0.06242167  0.11076207 -0.00185279 -0.17291354\n",
      "  -0.09076112  0.08514162  0.02970646  0.02206175  0.07996388 -0.04562465\n",
      "   0.00102812  0.03512584  0.00333163  0.09045057  0.05510951  0.04380744\n",
      "   0.09134878 -0.06562272 -0.02492725 -0.12497678 -0.1699839   0.21329382\n",
      "  -0.09949098  0.02986559]]\n"
     ]
    }
   ],
   "source": [
    "print database['ketan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GRADED FUNCTION: who_is_it# GRADED \n",
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the happy house by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    database -- database containing image encodings along with the name of the person on the image\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "    identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    \n",
    "    start = time.time()\n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    \n",
    "    # Initialize \"min_dist\" to a large value, say 100 (≈1 line)\n",
    "    min_dist = 100\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database. (≈ 1 line)\n",
    "        dist = np.linalg.norm(db_enc - encoding, ord=2)\n",
    "        print \"distance from photo to %s is %s\" % (name, dist)\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "    print \"Face identification took %s secs\" % (time.time() - start)    \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection took 0.690312862396 secs\n",
      "Face alignment took 0.00521802902222 secs\n",
      "Forward pass took 0.0354208946228 secs\n",
      "distance from photo to ketan is 0.5048104\n",
      "distance from photo to parker is 1.482557\n",
      "distance from photo to aditya is 1.0712059\n",
      "distance from photo to sid is 0.83026433\n",
      "it's ketan, the distance is 0.5048104\n",
      "Face identification took 0.00132703781128 secs\n",
      "Total time taken: 0.736959934235\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "who_is_it('/Users/ketanagrawal/Desktop/image-test/ketan-2.jpg', database, model)\n",
    "# who_is_it('/Users/ketanagrawal/Desktop/image-test/ketan-5.jpg', database, model)\n",
    "end = time.time()\n",
    "print \"Total time taken: %s\" % (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
